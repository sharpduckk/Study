{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import preprocessing\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "NUM_CLASSES = 200\n",
    "NUM_IMAGES_PER_CLASS = 500\n",
    "# NUM_IMAGES = NUM_CLASSES * NUM_IMAGES_PER_CLASS\n",
    "NUM_IMAGES = 98179\n",
    "TRAINING_IMAGES_DIR = '../tiny-imagenet-200/train/'\n",
    "TRAIN_SIZE = NUM_IMAGES\n",
    "\n",
    "NUM_VAL_IMAGES = 9832\n",
    "VAL_IMAGES_DIR = '../tiny-imagenet-200/val/'\n",
    "IMAGE_SIZE = 64\n",
    "NUM_CHANNELS = 3\n",
    "IMAGE_ARR_SIZE = IMAGE_SIZE * IMAGE_SIZE * NUM_CHANNELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_images(image_dir, batch_size=500):\n",
    "    image_index = 0\n",
    "\n",
    "    images = np.ndarray(shape=(NUM_IMAGES, IMAGE_ARR_SIZE))\n",
    "    names = []\n",
    "    labels = []\n",
    "\n",
    "    print(\"Loading training images from \", image_dir)\n",
    "    # Loop through all the types directories\n",
    "    for type in os.listdir(image_dir):\n",
    "        if os.path.isdir(image_dir + type):\n",
    "            type_images = os.listdir(image_dir + type)\n",
    "            # Loop through all the images of a type directory\n",
    "            batch_index = 0;\n",
    "            # print (\"Loading Class \", type)\n",
    "            for image in type_images:\n",
    "                image_file = os.path.join(image_dir, type, image)\n",
    "\n",
    "                # reading the images as they are; no normalization, no color editing\n",
    "                image_data = mpimg.imread(image_file)\n",
    "                print ('Loaded Image', image_file, image_data.shape)\n",
    "                if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "                    images[image_index, :] = image_data.flatten()\n",
    "\n",
    "                    labels.append(type)\n",
    "                    names.append(image)\n",
    "\n",
    "                    image_index += 1\n",
    "                    batch_index += 1\n",
    "                if (batch_index >= batch_size):\n",
    "                    break;\n",
    "\n",
    "    print(\"Loaded Training Images\", image_index)\n",
    "    return (images, np.asarray(labels), np.asarray(names))\n",
    "\n",
    "\n",
    "def get_label_from_name(data, name):\n",
    "    for idx, row in data.iterrows():\n",
    "        if (row['File'] == name):\n",
    "            return row['Class']\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_validation_images(testdir, validation_data, batch_size=NUM_VAL_IMAGES):\n",
    "    labels = []\n",
    "    names = []\n",
    "    image_index = 0\n",
    "\n",
    "    images = np.ndarray(shape=(batch_size, IMAGE_ARR_SIZE))\n",
    "    val_images = os.listdir(testdir + '/images/')\n",
    "\n",
    "    # Loop through all the images of a val directory\n",
    "    batch_index = 0;\n",
    "\n",
    "    for image in val_images:\n",
    "        image_file = os.path.join(testdir, 'images/', image)\n",
    "        # print (testdir, image_file)\n",
    "\n",
    "        # reading the images as they are; no normalization, no color editing\n",
    "        image_data = mpimg.imread(image_file)\n",
    "        print ('Loaded Image', image_file, image_data.shape)\n",
    "        if (image_data.shape == (IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)):\n",
    "            images[image_index, :] = image_data.flatten()\n",
    "            image_index += 1\n",
    "            labels.append(get_label_from_name(validation_data, image))\n",
    "            names.append(image)\n",
    "            batch_index += 1\n",
    "\n",
    "        if (batch_index >= batch_size):\n",
    "            break;\n",
    "\n",
    "    print(\"Loaded Validation images \", image_index)\n",
    "    return (images, np.asarray(labels), np.asarray(names))\n",
    "\n",
    "\n",
    "def get_next_batch(batchsize=50):\n",
    "    for cursor in range(0, len(training_images), batchsize):\n",
    "        batch = []\n",
    "        batch.append(training_images[cursor:cursor + batchsize])\n",
    "        batch.append(training_labels_encoded[cursor:cursor + batchsize])\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TRAINING_IMAGES_DIR, VAL_IMAGES_DIR)\n",
    "training_images, training_labels, training_files = load_training_images(TRAINING_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(len(training_labels))\n",
    "training_images = training_images[shuffle_index]\n",
    "training_labels = training_labels[shuffle_index]\n",
    "training_files = training_files[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('training_images', training_images)\n",
    "# np.save('training_labels', training_labels)\n",
    "# np.save('training_files', training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_images = np.load('training_images.npy')\n",
    "# training_labels = np.load('training_labels.npy')\n",
    "# training_files = np.load('training_files.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 Training Labels [121  80  41  88 148  29 153 160 188  91 122 108  48  40  83 114   6 157\n",
      "  82 185 196 192  21  20  41  65 120  72  27 136]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "training_le = le.fit(training_labels)\n",
    "training_labels_encoded = training_le.transform(training_labels)\n",
    "print(\"First 30 Training Labels\", training_labels_encoded[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([121,  80,  41, ..., 178,  63,  30], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('training_labels_encoded', training_labels_encoded)\n",
    "# training_labels_encoded = np.load('training_labels_encoded.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Validation images  9832\n",
      "[107 139  90 138  67 135 198  38  88  63 107 107  11  42  51  23 167  78\n",
      " 195 134 162  27 170 197  38  71  35  69  51  83]\n"
     ]
    }
   ],
   "source": [
    "val_data = pd.read_csv(VAL_IMAGES_DIR + 'labels.txt', sep='\\t', header=None,\n",
    "                       names=['File', 'Class'])\n",
    "val_images, val_labels, val_files = load_validation_images(VAL_IMAGES_DIR, val_data)\n",
    "val_labels_encoded = training_le.transform(val_labels)\n",
    "print(val_labels_encoded[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('val_images', val_images)\n",
    "# np.save('val_labels', val_labels)\n",
    "# np.save('val_files', val_files)\n",
    "# val_images = np.load('val_images.npy')\n",
    "# val_labels = np.load('val_labels.npy')\n",
    "# val_files = np.load('val_files.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('val_labels_encoded', val_labels_encoded)\n",
    "# val_labels_encoded = np.load('val_labels_encoded.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107, 139,  90, ..., 106,   1,  61], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "# num_classes = 10\n",
    "num_classes = 200\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = training_images\n",
    "y_train = training_labels_encoded\n",
    "x_test = val_images\n",
    "y_test = val_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98179 train samples\n",
      "9832 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(98179, 12288)\n",
    "x_test = x_test.reshape(9832, 12288)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98179, 12288)\n",
      "(9832, 12288)\n",
      "(9832,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(val_labels_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train_ = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_ = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               6291968   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 200)               102600    \n",
      "=================================================================\n",
      "Total params: 6,657,224\n",
      "Trainable params: 6,657,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(512, activation='relu', input_shape=(12288,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_))\n",
    "score = model.evaluate(x_test, y_test_, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
